New uploads on arXiv(cs.CL)

### Patch-Level Training for Large Language Models (http://arxiv.org/abs/2407.12665v1) [pdf: http://arxiv.org/pdf/2407.12665v1]
- **Summary**: The paper addresses the training efficiency of Large Language Models (LLMs), which traditionally suffer from high computational costs due to token-level training. The authors propose 'patch-level training,' where multiple tokens are compressed into single patches to shorten sequence length. The language model is first trained on these patches, and then fine-tuned with token-level training to align with inference mode. This approach reportedly cuts computational costs by half without sacrificing performance. Experiments on models ranging from 370M to 2.7B parameters validate the efficacy of this method. The source code for the implementation is available online.

- **PhD-Level Questions**: [{'Question 1': 'Describe the primary motivation behind introducing patch-level training for LLMs, and explain how this method addresses the issue of computational cost. Illustrate your answer with relevant comparisons to token-level training.'}, {'Question 2': 'The paper claims that patch-level training reduces computational costs by 0.5x without compromising model performance. Critically evaluate the potential limitations of this method and discuss scenarios where this approach might not be effective or could introduce new challenges.'}, {'Question 3': "Patch-level training involves compressing multiple tokens into a single patch. Discuss the potential implications of this compression on the language model's ability to capture token-level nuances and finer linguistic details. How might this affect downstream tasks such as text generation and comprehension?"}, {'Question 4': 'In the context of the paper, elaborate on how the transition from patch-level training to token-level fine-tuning is handled. What are the possible risks and advantages of this sequential training process?'}, {'Question 5': 'Analyze the experiment design used in the paper to evaluate the effectiveness of patch-level training. What metrics and baselines were utilized, and how robust are the results across different model sizes (370M-2.7B parameters)?'}]



### Domain-specific or Uncertainty-aware models: Does it really make a difference for biomedical text classification? (http://arxiv.org/abs/2407.12626v1) [pdf: http://arxiv.org/pdf/2407.12626v1]
BioNLP 2024

- **Summary**: This paper examines the dual objectives of domain specificity and uncertainty awareness in pretrained language models (PLMs), particularly for mission-critical applications like those in biomedicine. It explores how these aspects influence the output probability distribution's entropy and finds that while domain specificity and uncertainty awareness can often coexist successfully, the specific task being addressed has a significant impact on the outcomes.

- **PhD-Level Questions**: [{'Question 1': "Explain the significance of entropy in the output probability distribution of a domain-specific Pretrained Language Model (PLM) and how it relates to the model's uncertainty awareness."}, {'Question 2': 'Discuss how the requirements of a specific task can impact the successful integration of domain specificity and uncertainty awareness in PLMs. Provide an example based on mission-critical settings such as biomedical applications.'}]



### Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences (http://arxiv.org/abs/2407.12620v1) [pdf: http://arxiv.org/pdf/2407.12620v1]
- **Summary**: The paper explores the applications of AI and modern NLP, focusing on Large Language Models (LLMs) to support the usage and documentation of endangered Indigenous languages. Addressing the unique ethical challenges posed when working with Indigenous communities, the researchers propose an AI development cycle centered on community engagement. They report success in fine-tuning state-of-the-art translators with minimal data and discuss strategies for avoiding common pitfalls. The paper also highlights prototypes developed in collaboration with Brazilian Indigenous communities for facilitating writing, and the development of Indigenous Language Models (ILMs) for creating tools like spell-checkers and next-word predictors. The ultimate goal discussed is the preservation of endangered languages through interactive language models.

- **PhD-Level Questions**: [{'Question 1': 'Explain the ethical challenges involved in applying AI and NLP technologies to Indigenous languages, and how does the proposed development AI cycle address these challenges?'}, {'Question 2': 'Discuss the methods and significance of fine-tuning state-of-the-art translators with tiny amounts of data in the context of Indigenous languages. What common pitfalls need to be avoided in this process?'}, {'Question 3': 'Describe the prototypes mentioned in the paper that were built to facilitate writing in Indigenous languages. How do these prototypes aim to ensure community engagement and usage?'}, {'Question 4': 'How can Indigenous Language Models (ILMs) be scaled and replicated, and what roles do they play in language preservation through technologies like spell-checkers and next-word predictors?'}, {'Question 5': 'What is the vision for future language documentation as proposed in the paper, and how do interactive language models contribute to the preservation of dying languages?'}]



New uploads on arXiv(cs.IR)

### AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases (http://arxiv.org/abs/2407.12784v1) [pdf: http://arxiv.org/pdf/2407.12784v1]
22 pages, 13 figures, 7 tables

- **Summary**: The paper presents a novel attack method called AgentPoison, designed to exploit vulnerabilities in large language model (LLM) agents that utilize a memory module or retrieval-augmented generation (RAG) mechanism. These agents rely on knowledge bases to inform task planning and execution, which makes them susceptible to unverified and potentially malicious information. AgentPoison is a backdoor attack that poisons the long-term memory or RAG knowledge base of these LLM agents. The attack works by generating optimized backdoor triggers that map triggered instances to a unique embedding space. This ensures that malicious demonstrations are retrieved when a user instruction contains the backdoor trigger, while benign instructions continue to perform normally. AgentPoison does not require extra model training or fine-tuning and offers high transferability, coherence, and stealthiness. The effectiveness of AgentPoison is demonstrated through experiments on three types of real-world LLM agents: autonomous driving, knowledge-intensive QA, and healthcare EHRAgent, achieving an over 80% attack success rate with minimal impact on benign performance and a poison rate less than 0.1%.

- **PhD-Level Questions**: [{'Question 1': "Explain the methodology of AgentPoison's backdoor attack and discuss how it ensures the high probability retrieval of malicious demonstrations while maintaining normal performance for benign instructions."}, {'Question 2': 'Evaluate the constraints and optimization process used in generating backdoor triggers in AgentPoison. How does the method ensure coherence and stealthiness in context?'}, {'Question 3': 'Compare and contrast AgentPoison with traditional backdoor attacks. What are the significant differences in terms of implementation, effectiveness, and impact on LLM agents?'}, {'Question 4': 'Discuss the implications of using a poisoned knowledge base or long-term memory on the safety and trustworthiness of LLM agents, particularly in critical applications like autonomous driving and healthcare.'}, {'Question 5': 'What are the potential defenses against the AgentPoison backdoor attack? Propose a theoretical framework or mechanism to detect and mitigate such attacks in LLM agents utilizing memory or RAG.'}]



### E5-V: Universal Embeddings with Multimodal Large Language Models (http://arxiv.org/abs/2407.12580v1) [pdf: http://arxiv.org/pdf/2407.12580v1]
Code and models are available at https://github.com/kongds/E5-V

- **Summary**: The paper introduces E5-V, a novel framework designed to adapt multimodal large language models (MLLMs) for creating universal multimodal embeddings. Unlike previous methods, E5-V leverages MLLMs with prompts to bridge the modality gap between different input types without requiring fine-tuning. The framework employs a single modality training approach, using only text pairs for training, which drastically reduces training costs by 95% and avoids the need for expensive multimodal training data. The experimental results indicate that E5-V outperforms existing state-of-the-art models across multiple tasks, highlighting its effectiveness despite being trained on a single modality.

- **PhD-Level Questions**: [{'Question 1': 'Explain the advantages of using a single modality training approach over a traditional multimodal training in the context of the E5-V framework.'}, {'Question 2': 'How does E5-V bridge the modality gap between different types of inputs, and what role do prompts play in this process?'}, {'Question 3': "Discuss the potential implications of E5-V's ability to produce strong multimodal embeddings without fine-tuning. How might this impact future research and applications in the field?"}, {'Question 4': 'What experimental methods and tasks were used to validate E5-V’s performance, and what were the key findings in comparison to state-of-the-art models?'}, {'Question 5': 'Evaluate the cost-effectiveness of E5-V and its significance in reducing the dependency on multimodal training data. What challenges might still remain?'}]



### Search Engines, LLMs or Both? Evaluating Information Seeking Strategies for Answering Health Questions (http://arxiv.org/abs/2407.12468v1) [pdf: http://arxiv.org/pdf/2407.12468v1]
- **Summary**: The paper discusses the comparison between traditional web search engines and Large Language Models (LLMs) in the context of answering health-related questions. The study also evaluated retrieval-augmented generation (RAG) techniques. Key findings include that the quality of web pages remains relatively consistent further down the ranked list but that traditional search engines are less accurate than LLMs in answering health questions. LLMs, however, are sensitive to the input prompts they receive. Additionally, RAG approaches are highly effective in facilitating accurate information seeking.

- **PhD-Level Questions**: [{'Question 1': "Explain the significance of the finding that 'the quality of webpages potentially responding to a health question does not decline as we navigate further down the ranked lists.' How does this impact the use of traditional web search engines?"}, {'Question 2': 'Discuss the potential limitations and challenges that come with the sensitivity of LLMs to input prompts in the context of answering health-related questions. Provide strategies to mitigate these challenges.'}, {'Question 3': 'Critically evaluate the effectiveness of RAG in health information seeking based on the study’s findings. How does RAG compare to traditional web search engines and standalone LLMs?'}, {'Question 4': 'Based on the paper’s findings, outline a research proposal to further investigate one of the key areas identified in the study. Specify your research question, methodology, and expected outcomes.'}, {'Question 5': 'How could the findings of this study inform the design and improvement of future health information systems utilizing both web search engines and LLMs?'}]



### RankTower: A Synergistic Framework for Enhancing Two-Tower Pre-Ranking Model (http://arxiv.org/abs/2407.12385v1) [pdf: http://arxiv.org/pdf/2407.12385v1]
- **Summary**: The paper proposes a new neural network architecture called RankTower, designed to improve the efficiency and accuracy of the pre-ranking module in large-scale ranking systems. RankTower follows a user-item decoupling paradigm to ensure efficient online inference and employs a hybrid training objective to optimize different objectives for varying sample spaces. This novel approach aims to enhance the pre-ranking model's ranking capability and its alignment with the existing cascade ranking system. Experimental results on public datasets show that RankTower significantly outperforms state-of-the-art pre-ranking models.

- **PhD-Level Questions**: [{'Question 1': 'Explain the user-item decoupling paradigm and discuss how it contributes to the efficiency of the RankTower model.'}, {'Question 2': "Describe the hybrid training objective employed by RankTower. How does optimizing different objectives for varying sample spaces improve the model's ranking capability?"}, {'Question 3': 'Evaluate the significance of employing a cascading architecture in large-scale ranking systems. How does RankTower improve upon existing approaches within this framework?'}, {'Question 4': 'Critically analyze the experimental setup used to evaluate RankTower. What datasets were used, and what metrics were reported to demonstrate its efficacy over state-of-the-art pre-ranking models?'}, {'Question 5': 'How does RankTower maintain a balance between efficiency and accuracy while adhering to online latency constraints? Discuss the trade-offs involved in this balance.'}]



### Graph Signal Processing for Cross-Domain Recommendation (http://arxiv.org/abs/2407.12374v1) [pdf: http://arxiv.org/pdf/2407.12374v1]
- **Summary**: Cross-domain recommendation (CDR) extends traditional recommender systems by utilizing user-item interactions from dense domains to alleviate issues such as data sparsity and the cold start problem. Existing CDR methods often struggle with sensitivity to the ratio of overlapping users and the intrinsic discrepancies between source and target domains. To address these challenges, this paper introduces CGSP, a framework that leverages graph signal processing (GSP) for CDR. CGSP constructs a cross-domain similarity graph that integrates both target-only similarity and source-bridged similarity, enabling personalized graph signal processing for users across both domains. The empirical evaluation demonstrates that CGSP not only outperforms various encoder-based CDR approaches in both intra-domain and inter-domain recommendation scenarios but also excels particularly when there are few overlapping users, highlighting its potential utility in practical applications.

- **PhD-Level Questions**: [{'Question 1': 'Explain the primary challenges that most existing cross-domain recommendation (CDR) methods face. How does CGSP address these challenges?'}, {'Question 2': 'Describe the role of graph signal processing (GSP) in the CGSP framework. How does the integration of target-only similarity and source-bridged similarity contribute to its effectiveness?'}, {'Question 3': "Critically analyze the significance of CGSP's performance in scenarios with a low ratio of overlapping users. What are the potential implications for real-world applications?"}, {'Question 4': 'Discuss the construction of cross-domain similarity graphs in CGSP and how personalized graph signals are processed for users in both source and target domains.'}]



### Object-Aware Query Perturbation for Cross-Modal Image-Text Retrieval (http://arxiv.org/abs/2407.12346v1) [pdf: http://arxiv.org/pdf/2407.12346v1]
ECCV 2024

- **Summary**: This paper addresses the limitation of pre-trained vision and language (V&L) models in cross-modal image-text retrieval, particularly with small objects. Unlike human cognition which is object-centric and attentive to significant small objects, V&L models struggle with precise word-object alignment. The authors propose a framework called 'object-aware query perturbation' to enhance object awareness without requiring additional fine-tuning. This method generates a key feature subspace for detected objects and perturbs query vectors accordingly to better align text with important image features. Experiments across four datasets demonstrate the superiority of this approach over conventional methods.

- **PhD-Level Questions**: [{'Question 1': "Explain the concept of 'object-aware query perturbation' and how it improves cross-modal image-text retrieval. Discuss its impact on the alignment between small objects in images and corresponding textual descriptions."}, {'Question 2': "Compare the proposed method with traditional fine-tuning approaches for improving V&L model performance. What are the advantages of using the 'object-aware query perturbation' technique in terms of computational efficiency and generalization performance?"}, {'Question 3': 'Analyze the experimental methodology used by the authors to validate their framework. How do the datasets and metrics chosen contribute to demonstrating the effectiveness of the proposed method?'}, {'Question 4': "Discuss potential limitations or challenges of the 'object-aware query perturbation' technique. How might these be addressed in future work to further close the gap between human cognition and V&L model capabilities?"}]



### GUME: Graphs and User Modalities Enhancement for Long-Tail Multimodal Recommendation (http://arxiv.org/abs/2407.12338v1) [pdf: http://arxiv.org/pdf/2407.12338v1]
11 pages, accepted by CIKM 2024

- **Summary**: The paper addresses challenges in Multimodal Recommendation Systems (MMRS) that utilize user behavior and product information from images and text. Traditional approaches often struggle with long-tail items (low interaction data) and simple user modality representations. This study introduces a novel Graphs and User Modalities Enhancement (GUME) method to tackle these issues. The GUME approach enhances user-item graphs with multimodal item similarities to better represent long-tail items. It also constructs two types of user modalities: explicit interaction features and extended interest features, and uses a modality enhancement strategy to maximize mutual information and improve generalization. Additionally, the method includes an alignment strategy to reduce noise in modality data. Experiments on four datasets show the proposed method's effectiveness.

- **PhD-Level Questions**: [{'Question 1': 'How does the GUME method improve the connectivity of long-tail items in multimodal recommendation systems, and what is the role of graph propagation in this process?'}, {'Question 2': 'Describe the construction of explicit interaction features and extended interest features for user modalities. How does the modality enhancement strategy maximize mutual information between these two features?'}, {'Question 3': 'Explain the modality alignment strategy in GUME. How does it contribute to noise reduction from both internal and external perspectives?'}, {'Question 4': 'Evaluate the effectiveness of GUME based on the results from the four publicly available datasets. What metrics were used, and what improvements were observed compared to previous methods?'}, {'Question 5': 'Discuss the potential impact of improving long-tail item recommendations on overall user experience and engagement in MMRS. What challenges might arise when implementing GUME in real-world applications?'}]



### Optimizing Query Generation for Enhanced Document Retrieval in RAG (http://arxiv.org/abs/2407.12325v1) [pdf: http://arxiv.org/pdf/2407.12325v1]
- **Summary**: The paper discusses the challenges of 'hallucinations' in Large Language Models (LLMs), where they generate incorrect information. To address this, the Retrieval-Augmented Generation (RAG) method integrates document retrieval to enhance response accuracy. However, RAG still encounters hallucinations due to vague queries. This study proposes an improvement by optimizing query generation through a query-document alignment score and refining queries using LLMs for more precise and efficient document retrieval. The experiments indicate an average accuracy improvement of 1.6%.

- **PhD-Level Questions**: [{'Question 1': 'How does the query-document alignment score contribute to mitigating hallucinations in the context of Retrieval-Augmented Generation (RAG)?'}, {'Question 2': "Discuss the implications of refining queries using LLMs on the overall performance of document retrieval systems as suggested by the paper's findings."}]



### ModalChorus: Visual Probing and Alignment of Multi-modal Embeddings via Modal Fusion Map (http://arxiv.org/abs/2407.12315v1) [pdf: http://arxiv.org/pdf/2407.12315v1]
Accepted by VIS 2024

- **Summary**: The paper addresses the vulnerability of multi-modal embeddings, specifically CLIP embeddings, to cross-modal feature misalignment, which deteriorates model performance and generalization. The authors introduce ModalChorus, an interactive system designed to probe and align multi-modal embeddings effectively. ModalChorus operates in two main stages: embedding probing using a new dimensionality reduction method called Modal Fusion Map (MFM), and embedding alignment that supports user interaction for point-set and set-set alignments. MFM integrates both metric and nonmetric objectives to enhance modality fusion. The paper demonstrates that MFM outperforms other methods like t-SNE and MDS in maintaining proper cross-modal feature representation, as shown through quantitative and qualitative evaluations. Case studies highlight ModalChorus’s effectiveness in discovering and correcting misalignments in tasks such as zero-shot classification, cross-modal retrieval, and generation.

- **PhD-Level Questions**: [{'Question 1': 'Discuss the main limitations of current multi-modal embeddings such as CLIP embeddings as identified in the paper. How does the proposed ModalChorus system address these limitations, specifically through the use of Modal Fusion Map (MFM)?'}, {'Question 2': 'Explain the workings of Modal Fusion Map (MFM) in detail. How does it differ from traditional dimensionality reduction methods like t-SNE and MDS? Why is it more effective in integrating metric and nonmetric objectives for modality fusion?'}, {'Question 3': 'Evaluate the quantitative and qualitative metrics used in the paper to compare the performance of MFM with existing methods. How do these metrics substantiate the claims made by the authors regarding the superiority of MFM?'}, {'Question 4': 'How does the interactive alignment feature of ModalChorus enhance user control over point-set and set-set alignments? Provide examples from the case studies discussed in the paper.'}, {'Question 5': 'Reflect on the potential real-world applications of ModalChorus. How can it be utilized in scenarios such as zero-shot classification and cross-modal retrieval to improve overall effectiveness and reliability?'}]



### Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation (http://arxiv.org/abs/2407.12216v1) [pdf: http://arxiv.org/pdf/2407.12216v1]
- **Summary**: This study addresses the limitations of Large Language Models (LLMs) in handling knowledge-intensive queries, particularly in domain-specific and factual question-answering tasks. While Retrieval-augmented generation (RAG) systems incorporate external knowledge sources like structured knowledge graphs (KGs), LLMs still struggle with accurate responses despite having access to necessary facts. The paper analyzes error patterns in KG-based RAG methods, identifying eight critical failure points mainly due to insufficient focus on the question's intent and irrelevant fact gathering. To counter these issues, the paper introduces the Mindful-RAG approach, which emphasizes intent-based and contextually aligned knowledge retrieval, thus improving the correctness and relevance of LLM responses.

- **PhD-Level Questions**: [{'Question 1': 'What are the eight critical failure points identified in KG-based RAG methods, and how do they impact the quality of answers generated by LLMs?'}, {'Question 2': 'Explain the intent-based and contextually aligned knowledge retrieval method proposed by the Mindful-RAG framework. How does this approach specifically mitigate the identified failure points?'}]



